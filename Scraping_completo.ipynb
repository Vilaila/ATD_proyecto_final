{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ebd766-31bf-4b52-ba4d-5256d0b5e185",
   "metadata": {},
   "source": [
    "**Scraping Laureados (selenium)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "619e1916-1513-4828-8277-223504501bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Iniciamos el navegador Chrome para realizar web scraping dinámico.\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Accedemos a la página de Wikipedia que contiene la lista de laureados por país.\n",
    "driver.get(\"https://es.wikipedia.org/wiki/Anexo:Laureados_de_los_Premios_Nobel_por_pa%C3%ADs\")\n",
    "\n",
    "# Cada país aparece como un encabezado <h3> con la clase 'mw-heading3'.\n",
    "# A partir de cada encabezado, extraeremos la lista de laureados asociada.\n",
    "paises = driver.find_elements(By.CLASS_NAME, 'mw-heading.mw-heading3')\n",
    "\n",
    "# Creamos el archivo CSV donde guardaremos los datos extraídos.\n",
    "with open(\"laureados.csv\", \"w\", encoding=\"utf-8\", newline='') as f:\n",
    "    \n",
    "    # Cabecera del archivo, usando ';' como separador.\n",
    "    f.write('pais;nombre;categoria;anyo\\n')\n",
    "\n",
    "    # Recorremos cada país encontrado en la página.\n",
    "    for pais in paises:\n",
    "\n",
    "        # El texto del encabezado incluye \"[editar]\" al final, así que eliminamos los últimos 8 caracteres.\n",
    "        pais_imp = pais.text[:-8]\n",
    "\n",
    "        # Cada país va seguido de una lista <ol> con los laureados.\n",
    "        # Usamos 'following-sibling::ol[1]' para obtener la primera lista que sigue al encabezado.\n",
    "        div_pais = pais.find_element(By.XPATH, \"./following-sibling::ol[1]\")\n",
    "\n",
    "        # Cada laureado está en un elemento <li> dentro de esa lista.\n",
    "        filas = div_pais.find_elements(By.TAG_NAME, \"li\")\n",
    "\n",
    "        # Procesamos cada laureado de la lista.\n",
    "        for i in filas:\n",
    "\n",
    "            # Sustituimos posibles guiones por comas para separar nombre, categoría y año.\n",
    "            i = i.text.replace('-', ',')\n",
    "\n",
    "            # Dividimos la línea en partes: [nombre, categoria, año]\n",
    "            i = i.split(',')\n",
    "\n",
    "            # Eliminamos espacios residuales en las partes posteriores al nombre.\n",
    "            for j in i[1:]:\n",
    "                j.replace(' ', '')\n",
    "\n",
    "            # Algunos laureados tienen información adicional (por ejemplo, nacionalidades múltiples).\n",
    "            # Si hay más de 3 elementos, nos quedamos solo con: nombre, categoría, año.\n",
    "            if len(i) > 3:\n",
    "                i = [i[0], i[-2], i[-1]]\n",
    "\n",
    "            # Excluimos la categoría de la Paz, ya que no forma parte del análisis.\n",
    "            if 'Paz' not in i[1]:\n",
    "\n",
    "                # Construimos la línea final del CSV.\n",
    "                texto = pais_imp + ';' + ';'.join(i)\n",
    "\n",
    "                # Eliminamos posibles asteriscos de Wikipedia.\n",
    "                texto = texto.replace('*', '')\n",
    "\n",
    "                # Guardamos la línea en el archivo.\n",
    "                f.write(texto + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3286da1d-8bef-411f-90da-73f54f923cbd",
   "metadata": {},
   "source": [
    "**Scraping de gasto en educación (selenium y filtrado con re)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3d29487-cad8-49ce-85a5-f25851038c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import re\n",
    "\n",
    "# Iniciamos el navegador Chrome para realizar web scraping dinámico.\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Accedemos a la página de DatosMacro con el gasto en educación (% del PIB).\n",
    "driver.get(\"https://datosmacro.expansion.com/estado/gasto/educacion\")\n",
    "\n",
    "# Cerramos el aviso de cookies para poder interactuar con la página.\n",
    "driver.find_element(By.ID, 'ue-disagree-notice-button').click()\n",
    "\n",
    "# Creamos el archivo CSV donde guardaremos los datos extraídos.\n",
    "with open(\"gasto_educacion2.csv\", \"w\", encoding=\"utf-8\", newline='') as f:\n",
    "    \n",
    "    # Cabecera del archivo, usando ';' como separador.\n",
    "    f.write('pais;anyo;gasto_pib\\n')\n",
    "\n",
    "    # La tabla está paginada: avanzamos página a página hasta que no queden más.\n",
    "    while True:\n",
    "        try:\n",
    "            # Localizamos la tabla principal de datos.\n",
    "            tabla = driver.find_element(By.ID, 'tb1')\n",
    "\n",
    "            # Extraemos todas las filas (<tr>) de la tabla.\n",
    "            texto = tabla.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "            # La primera fila contiene los títulos, el resto son datos.\n",
    "            cuerpo = texto[1:]\n",
    "\n",
    "            # Recorremos cada fila de datos.\n",
    "            for linea in cuerpo:\n",
    "                try:\n",
    "                    # Extraemos el nombre del país usando una expresión regular.\n",
    "                    # Busca un texto que empiece en mayúscula y termine en minúscula.\n",
    "                    nombre = re.findall(r'[A-ZÁÉÍÓÚ].+[a-záéíúó]', linea.text)\n",
    "\n",
    "                    # Extraemos el año (columna con clase 'fecha').\n",
    "                    anyo = linea.find_element(By.CLASS_NAME, 'fecha')\n",
    "\n",
    "                    # Extraemos todas las columnas numéricas.\n",
    "                    numeros = linea.find_elements(By.CLASS_NAME, 'numero')\n",
    "\n",
    "                    # El gasto en educación (% PIB) está en la cuarta columna empezando por el final.\n",
    "                    # Aclaración: En la página web es la tercera columna, pero al inspeccionar la página \n",
    "                    # vemos que hay una columna extra llamada \"numero dol\" (Gasto Educación Per Cápita en dólares).\n",
    "                    gasto_PIB = numeros[-4]\n",
    "\n",
    "                    # Guardamos la línea en el CSV.\n",
    "                    f.write(f'{nombre[0]};{anyo.text};{gasto_PIB.text}\\n')\n",
    "\n",
    "                except:\n",
    "                    # Algunas filas pueden no tener datos completos, las ignoramos.\n",
    "                    pass\n",
    "\n",
    "            # Pasamos a la página anterior (la web ordena los años de más reciente a más antiguo).\n",
    "            driver.find_element(By.CLASS_NAME, 'float-start.padleft').click()\n",
    "\n",
    "        except:\n",
    "            # Si Selenium no encuentra la tabla o el botón de navegación,\n",
    "            # significa que hemos llegado al final de las páginas.\n",
    "            break\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18d8aa3-63a9-49ed-805a-760085c6e713",
   "metadata": {},
   "source": [
    "**Scraping de gasto en investigación (GET HTTP y normalización de nombres)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "672c43fa-553b-49b3-bec3-bc699316b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Diccionario para traducir los nombres de países del inglés (OWID) al español, garantizando coherencia con el dataset de laureados.\n",
    "paises = {\"Germany\": \"Alemania\", \n",
    "          \"Argentina\": \"Argentina\",\n",
    "          \"Australia\": \"Australia\",\n",
    "          \"Austria\": \"Austria\",\n",
    "          \"Azerbaijan\":\"Azerbaiyán\",\n",
    "          \"Belgium\": \"Bélgica\",\n",
    "          \"Belarus\": \"Bielorrusia\",\n",
    "          \"Bosnia and Herzegovina\": \"Bosnia y Herzegovina\",\n",
    "          \"Bulgaria\": \"Bulgaria\",\n",
    "          \"Canada\": \"Canadá\",\n",
    "          \"Czechia\":\"República Checa\",\n",
    "          \"Chile\":\"Chile\",\n",
    "          \"China\":\"República Popular China\",\n",
    "          \"Cyprus\":\"Chipre\",\n",
    "          \"Colombia\":\"Colombia\",\n",
    "          \"South Korea\":\"Corea del Sur\", \n",
    "          \"Croatia\":\"Croacia\",\n",
    "          \"Denmark\":\"Dinamarca\", \n",
    "          \"Egypt\":\"Egipto\",\n",
    "          \"Slovenia\":\"Eslovenia\",\n",
    "          \"Spain\":\"España\",\n",
    "          \"United States\": \"Estados Unidos\", \n",
    "          \"Faroe Islands\":\"Islas Feroe\",\n",
    "          \"Finland\":\"Finlandia\",\n",
    "          \"France\":\"Francia\", \n",
    "          \"Greece\":\"Grecia\",\n",
    "          \"Guatemala\":\"Guatemala\", \n",
    "          \"Hong Kong\":\"Hong Kong\",\n",
    "          \"Hungary\":\"Hungría\",\n",
    "          \"India\":\"India\",\n",
    "          \"Ireland\":\"Irlanda\",\n",
    "          \"Israel\":\"Israel\",\n",
    "          \"Italy\":\"Italia\",\n",
    "          \"Iceland\":\"Islandia\",\n",
    "          \"Japan\":\"Japón\",\n",
    "          \"Lithuania\":\"Lituania\",\n",
    "          \"Luxembourg\":\"Luxemburgo\",\n",
    "          \"Mexico\": \"México\",\n",
    "          \"Nigeria\":\"Nigeria\",\n",
    "          \"Norway\":\"Noruega\", \n",
    "          \"New Zealand\":\"Nueva Zelanda\",\n",
    "          \"Netherlands\":\"Países Bajos\",\n",
    "          \"Pakistan\":\"Pakistán\",\n",
    "          \"Peru\":\"Perú\",\n",
    "          \"Poland\":\"Polonia\",\n",
    "          \"Portugal\":\"Portugal\",\n",
    "          \"United Kingdom\":\"Reino Unido\",\n",
    "          \"Romania\":\"Rumania\",\n",
    "          \"Russia\":\"Rusia y Unión Soviética\",\n",
    "          \"Saint Lucia\": \"Santa Lucía\",\n",
    "          \"South Africa\":\"Sudáfrica\",\n",
    "          \"Sweden\":\"Suecia\",\n",
    "          \"Switzerland\":\"Suiza\",\n",
    "          \"Trinidad and Tobago\": \"Trinidad y Tobago\",\n",
    "          \"Turkey\":\"Turquía\",\n",
    "          \"Ukraine\":\"Ucrania\",\n",
    "          \"Venezuela\":\"Venezuela\"}\n",
    "\n",
    "# Descargamos el CSV de Our World in Data mediante una petición HTTP.\n",
    "# Este archivo contiene el gasto en I+D (% del PIB) por país y año.\n",
    "url = \"https://ourworldindata.org/grapher/research-spending-gdp.csv\"\n",
    "texto = requests.get(url).text\n",
    "\n",
    "# Convertimos el CSV en una lista de líneas para procesarlo manualmente.\n",
    "l = texto.split(\"\\n\") \n",
    "\n",
    "\n",
    "# Creamos un nuevo CSV filtrado y traducido, solo con los países que aparecen en el dataset de laureados.\n",
    "with open(\"research_spending.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "\n",
    "    # Cabecera del nuevo archivo, usando ';' como separador.\n",
    "    f.write(\"pais;codigo;anyo;investigacion_pib\\n\")\n",
    "\n",
    "    # Recorremos cada línea del CSV original.\n",
    "    for linea in l:\n",
    "        # Comprobamos si la línea pertenece a un país relevante.\n",
    "        for en, es in paises.items():\n",
    "            if linea.startswith(en + \",\"):\n",
    "\n",
    "                # Sustituimos el nombre del país por su traducción al español.\n",
    "                linea = linea.replace(en, es, 1)\n",
    "\n",
    "                # Cambiamos el separador ',' por ';'.\n",
    "                linea = linea.replace(\",\", \";\") \n",
    "                \n",
    "                # Escribimos la línea traducida y filtrada en el nuevo archivo.\n",
    "                f.write(linea + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
